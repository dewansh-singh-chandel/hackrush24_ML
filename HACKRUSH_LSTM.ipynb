{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eb5MDTxoo6Aj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = \"cuda\"  if torch.cuda.is_available() else \"cpu\"\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.load(\"/content/X_train_up.npy\")\n",
        "X_test = np.load(\"/content/X_test_up (1).npy\")"
      ],
      "metadata": {
        "id": "P78YBNKQLrI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components =13)\n",
        "\n",
        "X_train_tr = []\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "\n",
        "    tt  =  pca.fit_transform(X_train[i])\n",
        "    X_train_tr.append(tt)\n",
        "X_train_tr = np.array(X_train_tr)"
      ],
      "metadata": {
        "id": "W1RBA_TVWxjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_tr = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "\n",
        "    tt  =  pca.fit_transform(X_test[i])\n",
        "    X_test_tr.append(tt)\n",
        "X_test_tr = np.array(X_test_tr)"
      ],
      "metadata": {
        "id": "Mj6u2_r3Y18O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train =  torch.tensor(X_train_tr,requires_grad= True).to(device)\n",
        "X_test =  torch.tensor(X_test_tr,requires_grad = True).to(device)"
      ],
      "metadata": {
        "id": "s_YQQJYfMNyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_NrXQrfkOmPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBHGOJlNM9m2",
        "outputId": "4fcd1810-b39c-4437-94d9-638afb1accc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([224, 750, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train  = torch.load(\"/content/y_train.pt\",map_location = device)\n",
        "y_test = torch.load(\"/content/y_test.pt\",map_location = device)\n"
      ],
      "metadata": {
        "id": "KN09MRsbqQTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y_train)):\n",
        "    y_train[i]-=1;\n",
        "for i in range(len(y_test)):\n",
        "    y_test[i]-=1;\n"
      ],
      "metadata": {
        "id": "9KM8_Wp4qmW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DTv2tnFNsTZ",
        "outputId": "497c0294-72cd-458c-a29f-8873204c443f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([56, 750, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=10\n",
        "train_loader = DataLoader(TensorDataset(X_train,y_train), batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test,y_test), batch_size=10,shuffle = True)\n"
      ],
      "metadata": {
        "id": "rS9kCgfXqvGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "RMmwJqH_qx8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5RoOTiP6KWXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for model 5 and 6\n",
        "# input_size = 32\n",
        "# hidden_size = 64\n",
        "# num_layers = 6\n",
        "# num_classes = 9\n",
        "# learning_rate = 0.001\n",
        "\n",
        "input_size = 13\n",
        "hidden_size = 64\n",
        "num_layers = 6\n",
        "num_classes = 9\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = LSTMClassifier(input_size,hidden_size,num_layers,num_classes).to(device)"
      ],
      "metadata": {
        "id": "vUUr-ervq8lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = LSTMClassifier(32,64,6,9)\n",
        "# # model.state_dict()\n",
        "\n",
        "# model.load_state_dict(torch.load('/content/model_5.pth'))"
      ],
      "metadata": {
        "id": "1qZIbMgqFCZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "q0oiDMJ7q_Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (sequences, labels) in enumerate(train_loader):\n",
        "        sequences = sequences.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(sequences)\n",
        "        loss = criterion(outputs, labels.squeeze())\n",
        "        # print(loss)\n",
        "        # Backward and optimize\n",
        "\n",
        "        # loss.backward()\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "id": "7iK52GmaEdoi",
        "outputId": "0d20ab9f-123b-4d1c-fd9b-2d5e6ad86944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Step [10/23], Loss: 2.2214\n",
            "Epoch [1/20], Step [20/23], Loss: 2.2036\n",
            "Epoch [2/20], Step [10/23], Loss: 2.2337\n",
            "Epoch [2/20], Step [20/23], Loss: 2.2142\n",
            "Epoch [3/20], Step [10/23], Loss: 2.2075\n",
            "Epoch [3/20], Step [20/23], Loss: 2.1901\n",
            "Epoch [4/20], Step [10/23], Loss: 2.1476\n",
            "Epoch [4/20], Step [20/23], Loss: 2.2318\n",
            "Epoch [5/20], Step [10/23], Loss: 2.1508\n",
            "Epoch [5/20], Step [20/23], Loss: 2.1429\n",
            "Epoch [6/20], Step [10/23], Loss: 1.9912\n",
            "Epoch [6/20], Step [20/23], Loss: 2.3442\n",
            "Epoch [7/20], Step [10/23], Loss: 1.9490\n",
            "Epoch [7/20], Step [20/23], Loss: 1.9673\n",
            "Epoch [8/20], Step [10/23], Loss: 1.8060\n",
            "Epoch [8/20], Step [20/23], Loss: 1.7175\n",
            "Epoch [9/20], Step [10/23], Loss: 1.7491\n",
            "Epoch [9/20], Step [20/23], Loss: 1.7698\n",
            "Epoch [10/20], Step [10/23], Loss: 1.7069\n",
            "Epoch [10/20], Step [20/23], Loss: 1.4630\n",
            "Epoch [11/20], Step [10/23], Loss: 1.4942\n",
            "Epoch [11/20], Step [20/23], Loss: 1.3870\n",
            "Epoch [12/20], Step [10/23], Loss: 1.5385\n",
            "Epoch [12/20], Step [20/23], Loss: 2.0334\n",
            "Epoch [13/20], Step [10/23], Loss: 1.6649\n",
            "Epoch [13/20], Step [20/23], Loss: 1.4707\n",
            "Epoch [14/20], Step [10/23], Loss: 1.2275\n",
            "Epoch [14/20], Step [20/23], Loss: 1.1760\n",
            "Epoch [15/20], Step [10/23], Loss: 1.5039\n",
            "Epoch [15/20], Step [20/23], Loss: 0.7760\n",
            "Epoch [16/20], Step [10/23], Loss: 0.6489\n",
            "Epoch [16/20], Step [20/23], Loss: 0.9071\n",
            "Epoch [17/20], Step [10/23], Loss: 1.0899\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-8d5f37d1b1e4>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-112-c24de1f7d8cf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    879\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = 0\n",
        "with torch.inference_mode():\n",
        "    for sequences,label in train_loader:\n",
        "        sequences = sequences.to(device)\n",
        "        labels = labels.to(device)\n",
        "        preds = model(sequences)\n",
        "\n",
        "        preds =  torch.argmax(preds,axis =1)\n",
        "\n",
        "        train_acc += (preds==label.squeeze()).sum()\n",
        "\n",
        "print(f\"accuracy on training set {train_acc/len(y_train)}\")"
      ],
      "metadata": {
        "id": "2W1j1Z912rmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = 0\n",
        "with torch.inference_mode():\n",
        "    for sequences,label in test_loader:\n",
        "        sequences = sequences.to(device)\n",
        "        labels = labels.to(device)\n",
        "        preds = model(sequences)\n",
        "\n",
        "        preds =  torch.argmax(preds,axis =1)\n",
        "\n",
        "        test_acc += (preds==label.squeeze()).sum()\n",
        "\n",
        "print(f\"accuracy on testing set {test_acc/len(y_test)}\")"
      ],
      "metadata": {
        "id": "D5AJyrNOCFW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"model_7_pca.pth\")"
      ],
      "metadata": {
        "id": "dZw4c5JQ__zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ya_preds = model(X_test)\n"
      ],
      "metadata": {
        "id": "UdcpSn4hAHNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ya_preds = torch.argmax(ya_preds,axis =1)"
      ],
      "metadata": {
        "id": "nr9z7LaxB0fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.squeeze()"
      ],
      "metadata": {
        "id": "fd1Ge3XEApOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Ct6JE7qAdE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yMUpvAWy_9AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics  import accuracy_score\n",
        "\n",
        "accuracy_score(y_test.view(-1,1).squeeze().detach().numpy(),ya_preds.detach().cpu())\n"
      ],
      "metadata": {
        "id": "sdnAWUY_z72Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1SHvDTY1K_F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# test = pd.read_excel(\"/content/Test.xlsx\")\n",
        "\n",
        "# test = test.drop(columns= [\"ID\"])\n",
        "# test = test.values\n",
        "\n",
        "# test = torch.tensor(test,dtype = torch.float32)\n",
        "# def create_data_pt(random_tensor: torch.Tensor)->torch.Tensor:\n",
        "\n",
        "#     le =  int(random_tensor.shape[0]/32)\n",
        "\n",
        "#     arr = torch.zeros(le,random_tensor.shape[1]-1,32).to(device)\n",
        "#     for i in range(le):\n",
        "\n",
        "#         data_pt = random_tensor[32*i: 32*(i+1),:-1]\n",
        "#         data_pt = data_pt.T\n",
        "# #         print(data_pt.shape)\n",
        "#         arr[i] =  data_pt\n",
        "\n",
        "\n",
        "#     return arr\n",
        "\n",
        "# test_points=  create_data_pt(test)\n",
        "\n",
        "# preds = model(test_points)\n",
        "# preds  = torch.argmax(preds ,axis=1)\n",
        "# preds = preds.numpy()\n",
        "\n",
        "\n",
        "\n",
        "# dictt = {0: 'Tiger',\n",
        "#     1: 'Snake',\n",
        "#     2: 'Wolf',\n",
        "#     3: 'Bear',\n",
        "#     4: 'Rabbit',\n",
        "#     5: 'Monkey',\n",
        "#     6: 'Eagle',\n",
        "#     7: 'Dolphin',\n",
        "#     8: 'Koala'}\n",
        "\n",
        "# arr1  = [ dictt[i]  for i in preds]\n",
        "# arr1"
      ],
      "metadata": {
        "id": "YPP_rCtF4kqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_point = torch.load(\"/content/test_points.pt\")\n",
        "test_point.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQXSo0OIUujZ",
        "outputId": "f6c2f1ec-9081-4701-84a8-5ae8aae35b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([271, 749, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_points = []\n",
        "\n",
        "for i in range(len(test_point)):\n",
        "\n",
        "    tt  =  pca.fit_transform(test_point[i].detach().cpu())\n",
        "    test_points.append(tt)\n",
        "test_points_pca = np.array(test_points)\n"
      ],
      "metadata": {
        "id": "9DBqhPOQfj8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_point.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu6WqYVHhSjs",
        "outputId": "513006f4-8904-493f-fb0b-ab2d75b0460a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([271, 749, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_point = torch.tensor(test_points_pca,dtype = torch.float32).to(device)"
      ],
      "metadata": {
        "id": "IQPsU8mZhX3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(test_point)\n",
        "preds  = torch.argmax(preds ,axis=1)\n",
        "preds = preds.numpy()\n",
        "\n",
        "\n",
        "\n",
        "dictt = {0: 'Tiger',\n",
        "    1: 'Snake',\n",
        "    2: 'Wolf',\n",
        "    3: 'Bear',\n",
        "    4: 'Rabbit',\n",
        "    5: 'Monkey',\n",
        "    6: 'Eagle',\n",
        "    7: 'Dolphin',\n",
        "    8: 'Koala'}\n",
        "\n",
        "arr1  = [ dictt[i]  for i in preds]\n",
        "arr1"
      ],
      "metadata": {
        "id": "0ii-qfGhIaU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(test_points,\"test_points.pt\")"
      ],
      "metadata": {
        "id": "Bcbru197DEkM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}